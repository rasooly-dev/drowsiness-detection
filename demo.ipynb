{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from cv2.data import haarcascades\n",
    "import os\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from pygame import mixer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer.init()\n",
    "sound = mixer.Sound('assets/alert.wav')\n",
    "\n",
    "# sound.play()\n",
    "# time.sleep(0.2)\n",
    "# sound.stop()\n",
    "# time.sleep(0.5)\n",
    "# sound.play()\n",
    "# time.sleep(0.2)\n",
    "# sound.stop()\n",
    "# time.sleep(0.4)\n",
    "# sound.play()\n",
    "# time.sleep(0.2)\n",
    "# sound.stop()\n",
    "# time.sleep(0.3)\n",
    "# sound.play()\n",
    "# time.sleep(0.2)\n",
    "# sound.stop()\n",
    "# time.sleep(0.2)\n",
    "# sound.play()\n",
    "# time.sleep(0.2)\n",
    "# sound.stop()\n",
    "# time.sleep(0.1)\n",
    "# sound.play()\n",
    "# time.sleep(1)\n",
    "# sound.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "left_eye_cascade = cv2.CascadeClassifier(haarcascades + 'haarcascade_lefteye_2splits.xml')\n",
    "right_eye_cascade = cv2.CascadeClassifier(haarcascades + 'haarcascade_righteye_2splits.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_model = load_model('models/CNN_eye_normal.keras')\n",
    "yawn_model = load_model('models/yawn_detection_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leftmost_eye(eyes):\n",
    "    leftmost = float('inf')\n",
    "    leftmost_eye = None\n",
    "    for i, eye in enumerate(eyes):\n",
    "        if eye[0].any() < leftmost:\n",
    "            leftmost = eye[0]\n",
    "            leftmost_eye = eye\n",
    "    return leftmost_eye\n",
    "\n",
    "def get_rightmost_eye(eyes):\n",
    "    rightmost = -1\n",
    "    rightmost_eye = None\n",
    "    for i, eye in enumerate(eyes):\n",
    "        if eye[0].any() > rightmost:\n",
    "            rightmost = eye[0]\n",
    "            rightmost_eye = eye\n",
    "    return rightmost_eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "[44 48 31 31]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "[39 43 31 31]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "[46 47 32 32]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "[43 48 26 26]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "[43 46 30 30]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Error opening video capture')\n",
    "    exit(1)\n",
    "\n",
    "score = 0\n",
    "score_threshold = 15\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print('Error reading video frame')\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = frame[y:y+h, x:x+w]\n",
    "        face_gray = gray[y:y+h, x:x+w]\n",
    "\n",
    "        eyes = []\n",
    "        left_eye = left_eye_cascade.detectMultiScale(face_gray, 1.3, 5)\n",
    "        for (ex, ey, ew, eh) in left_eye:\n",
    "            eyes.append(face[ey:ey+eh, ex:ex+ew])\n",
    "            # cv2.rectangle(face, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
    "            # cv2.putText(face, 'Left Eye', (ex, ey), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        right_eye = right_eye_cascade.detectMultiScale(face_gray, 1.3, 5)\n",
    "        for (ex, ey, ew, eh) in right_eye:\n",
    "            eyes.append(face[ey:ey+eh, ex:ex+ew])\n",
    "            # cv2.rectangle(face, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
    "            # cv2.putText(face, 'Right Eye', (ex, ey), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        # cv2.putText(frame, 'Face', (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        face_gray = cv2.resize(face_gray, (150, 150))\n",
    "        face_gray = face_gray.reshape(1, 150, 150, 1)\n",
    "        face_gray = face_gray / 255.0\n",
    "\n",
    "        yawn_pred = yawn_model.predict(face_gray)\n",
    "        if yawn_pred[0] > 0.5:\n",
    "            # cv2.putText(frame, 'Yawn Detected', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            score += 1\n",
    "            if score > score_threshold:\n",
    "                score = score_threshold + 1\n",
    "            # sound.play()\n",
    "        else:\n",
    "            score -= 1\n",
    "            # sound.stop()\n",
    "\n",
    "        leftmost_eye = get_leftmost_eye(left_eye)\n",
    "        rightmost_eye = get_rightmost_eye(right_eye)\n",
    "        for eye in [leftmost_eye, rightmost_eye]:\n",
    "            if eye is None:\n",
    "                continue\n",
    "            print(eye)\n",
    "            ex, ey, ew, eh = eye\n",
    "            eye = face[ey:ey+eh, ex:ex+ew]\n",
    "            # cv2.rectangle(face, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
    "            # cv2.putText(face, 'Eye', (ex, ey), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            eye_gray = cv2.cvtColor(eye, cv2.COLOR_BGR2GRAY)\n",
    "            eye_gray = cv2.resize(eye_gray, (250, 250))\n",
    "            eye_gray = eye_gray.reshape(1, 250, 250, 1)\n",
    "            eye_gray = eye_gray / 255.0\n",
    "            \n",
    "            eye_pred = eye_model.predict(eye_gray)\n",
    "            if eye_pred[0] < 0.5:\n",
    "                # cv2.putText(frame, 'Eye Closed', (x, y-30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                score += 1\n",
    "                if score > score_threshold:\n",
    "                    score = score_threshold + 1\n",
    "                # sound.play()\n",
    "            else:\n",
    "                score -= 1\n",
    "                # sound.stop()\n",
    "        \n",
    "        if score < 0:\n",
    "            score = 0\n",
    "        \n",
    "        if score > score_threshold:\n",
    "            cv2.putText(frame, 'Drowsiness Detected', (x, y-50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "            # check if sound is already playing\n",
    "            if not mixer.get_busy():\n",
    "                sound.play()\n",
    "        else:\n",
    "            sound.stop()\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECS174Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
